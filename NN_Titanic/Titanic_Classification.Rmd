---
title: "Neural Network with the Titanic Data"
author: "by Xuxi Zhu"
date: "3/11/2022"
output:
  html_document:
    df_print: paged
---

# 0. Preparation
```{r}
library(tidyverse)
library(caret)
library(neuralnet)
library(keras)
library(e1071)
# The file path may vary in different computers
setwd('/Users/zhuxuxi/Desktop/AMS_SBU/2022_AMS_580/NN_Titanic')
```

# 1. Read data & split Data
```{r}
training.data.raw <- read.csv('Titanic.csv')
my_data <- subset(training.data.raw,select=c(2,3,5,6,7,8,10,12))
my_data <- na.omit(my_data)
sum(is.na(my_data))
```
`r length(my_data$Survived)` passengers are left.

```{r}
set.seed(123)
training.samples <- my_data$Survived %>% 
  createDataPartition(p = 0.75, list = FALSE)
train.data  <- my_data[training.samples, ]
test.data <- my_data[-training.samples, ]
```

# 2. SSE with no hidden layer
```{r}
m_train <- model.matrix( 
  ~ Survived + Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, 
  data = train.data 
)
#as.data.frame(m)
model <- neuralnet( 
  Survived ~ Pclass+Sexmale+Age+SibSp+Parch+Fare+EmbarkedC+EmbarkedQ+EmbarkedS, 
  data=m_train, hidden = 0, err.fct = "sse", linear.output = F)
plot(model, rep = "best")
```

```{r}
m_test <- model.matrix( 
  ~ Survived + Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, 
  data = test.data 
)
probabilities <- model %>% predict(m_test) %>% as.vector()
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
confusionMatrix(factor(predicted.classes), factor(test.data$Survived), positive = '1')
```

# 3. CE with no hidden layer
```{r}
set.seed(123)
model <- neuralnet(Survived ~ Pclass+Sexmale+Age+SibSp+Parch+Fare+EmbarkedC+EmbarkedQ+EmbarkedS, data = m_train, hidden = 0, err.fct = "ce", linear.output = F)
plot(model, rep = "best")
```

```{r}
probabilities <- model %>% predict(m_test)
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
confusionMatrix(factor(predicted.classes), factor(test.data$Survived), positive = '1')
```


# 4. Logistic Regression
```{r}
set.seed(123)
model <- glm(Survived~., family = binomial, data = train.data)
model
```
```{r}
probabilities <- model %>% predict(test.data, type = 'response')
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
confusionMatrix(factor(predicted.classes), factor(test.data$Survived), positive = '1')
```
The CE Loss function model better ensembles logistic regression model.

# 5. SSE with one hidden layer with 3 neurons
```{r}
set.seed(123)
model <- neuralnet(Survived ~ Pclass+Sexmale+Age+SibSp+Parch+Fare+EmbarkedC+EmbarkedQ+EmbarkedS, data = m_train, hidden = 3, err.fct = "sse", linear.output = F)
plot(model, rep = "best")
```

```{r}
probabilities <- model %>% predict(m_test)
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
confusionMatrix(factor(predicted.classes), factor(test.data$Survived), positive = '1')
```

The prediction with hidden layer is better than no hidden layer.

# 6. CE with one hidden layer with 3 neurons
```{r}
set.seed(123)
model <- neuralnet(Survived ~Pclass+Sexmale+Age+SibSp+Parch+Fare+EmbarkedC+EmbarkedQ+EmbarkedS, data = m_train, hidden = 3, err.fct = "ce", linear.output = F)
plot(model, rep = "best")
```
```{r}
probabilities <- model %>% predict(m_test)
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
confusionMatrix(factor(predicted.classes), factor(test.data$Survived), positive = '1')
```

The prediction with hidden layer is better than no hidden layer.


# ---------The End---------
